#!/usr/bin/env julia

"""
    test_retraining_syntax.jl

Simple test script to verify syntax and basic functionality before running full retraining.
"""

using Pkg
Pkg.activate(".")

# Add src to load path
push!(LOAD_PATH, joinpath(@__DIR__, "..", "src"))

# Load required modules
include(joinpath(@__DIR__, "..", "src", "training.jl"))
include(joinpath(@__DIR__, "..", "src", "neural_ode_architectures.jl"))

using DifferentialEquations
using Flux
using Optim
using Statistics
using Random
using LinearAlgebra
using CSV
using DataFrames
using BSON
using Turing
using MCMCChains
using Distributions
using HypothesisTests
using Dates

println("üß™ TESTING RETRAINING SCRIPT SYNTAX")
println("=" ^ 50)

# Test 1: Load data
println("üìä Test 1: Loading data...")
data_path = joinpath(@__DIR__, "..", "data", "training_dataset_fixed.csv")
if !isfile(data_path)
    error("Training data not found at: $data_path")
end

df = CSV.read(data_path, DataFrame)
println("  ‚úÖ Data loaded: $(nrow(df)) samples")

# Test 2: UDE model definition
println("üîß Test 2: UDE model definition...")
function ude_nn(x, params)
    nn_weights = params[6:end]
    W1 = reshape(nn_weights[1:10], 5, 2)
    b1 = nn_weights[11:15]
    h = tanh.(W1 * x + b1)
    output = sum(h)
    return output
end

function ude_system!(du, u, p, t)
    x1, x2 = u
    Œ∑in, Œ∑out, Œ±, Œ≤, Œ≥ = p[1:5]
    neural_correction = ude_nn([x1, x2], p)
    du[1] = Œ∑in * (1 - x1) - Œ± * x1 + neural_correction
    du[2] = Œ≤ * (x1 - 0.5) - Œ≥ * x2 + neural_correction
end

println("  ‚úÖ UDE model defined")

# Test 3: BNode model definition
println("üîÆ Test 3: BNode model definition...")
@model function bnode_model(t_data, Y_data)
    Œ∑in ~ Normal(0.9, 0.1)
    Œ∑out ~ Normal(0.9, 0.1)
    Œ± ~ Normal(0.001, 0.001)
    Œ≤ ~ Normal(1.0, 0.1)
    Œ≥ ~ Normal(0.001, 0.001)
    nn_weights ~ MvNormal(zeros(15), 0.1 * I)
    params = vcat([Œ∑in, Œ∑out, Œ±, Œ≤, Œ≥], nn_weights)
    
    function bnode_system!(du, u, p, t)
        x1, x2 = u
        Œ∑in, Œ∑out, Œ±, Œ≤, Œ≥ = p[1:5]
        nn_weights = p[6:end]
        W1 = reshape(nn_weights[1:10], 5, 2)
        b1 = nn_weights[11:15]
        inputs = [x1, x2]
        h = tanh.(W1 * inputs + b1)
        neural_correction = sum(h)
        du[1] = Œ∑in * (1 - x1) - Œ± * x1 + neural_correction
        du[2] = Œ≤ * (x1 - 0.5) - Œ≥ * x2 + neural_correction
    end
    
    prob = ODEProblem(bnode_system!, [0.5, 0.0], (minimum(t_data), maximum(t_data)), params)
    sol = solve(prob, Tsit5(); saveat=t_data, abstol=1e-6, reltol=1e-6)
    
    if sol.retcode != :Success
        Turing.@addlogprob! -Inf
        return
    end
    
    Y_pred = hcat([sol(t) for t in t_data]...)
    Y_pred = Y_pred'
    
    œÉ ~ Exponential(1.0)
    for i in 1:size(Y_data, 1)
        Y_data[i, :] ~ MvNormal(Y_pred[i, :], œÉ * I)
    end
end

println("  ‚úÖ BNode model defined")

# Test 4: Directory creation
println("üìÅ Test 4: Directory creation...")
results_dir = joinpath(@__DIR__, "..", "results")
checkpoints_dir = joinpath(@__DIR__, "..", "checkpoints")

if !isdir(results_dir)
    mkdir(results_dir)
end
if !isdir(checkpoints_dir)
    mkdir(checkpoints_dir)
end

println("  ‚úÖ Directories created")

# Test 5: Small ODE solve
println("üî¨ Test 5: Small ODE solve...")
t_test = [0.0, 0.1, 0.2]
params_test = vcat([0.9, 0.9, 0.001, 1.0, 0.001], randn(15) * 0.1)

prob_test = ODEProblem(ude_system!, [0.5, 0.0], (0.0, 0.2), params_test)
sol_test = solve(prob_test, Tsit5(); saveat=t_test, abstol=1e-6, reltol=1e-6)

if sol_test.retcode == :Success
    println("  ‚úÖ ODE solve successful")
else
    println("  ‚ö†Ô∏è ODE solve failed: $(sol_test.retcode)")
end

println("\nüéØ ALL TESTS COMPLETED SUCCESSFULLY!")
println("‚úÖ Script syntax is correct")
println("‚úÖ Basic functionality verified")
println("‚úÖ Ready to run full retraining") 